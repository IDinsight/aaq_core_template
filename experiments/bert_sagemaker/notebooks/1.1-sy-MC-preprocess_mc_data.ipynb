{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44485d9",
   "metadata": {},
   "source": [
    "# Preprocessing MomConnect Data\n",
    "\n",
    "\n",
    "1. Clean FAQs --> the \"user generated\" questions will be our training data\n",
    "2. Clean Validation data --> these will be our test data\n",
    "\n",
    "For QA+QQ combined, we need\n",
    "\n",
    "1. Reference questions -- random split from 1\n",
    "2. Training questions -- rest split from 1\n",
    "3. Test questions -- from 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "faqs = pd.read_csv('s3://praekelt-static-resources/experiment/data/[Sam] Helpdesk Q&A _ MOMZA _ FAQ Content.xlsx - FAQs.csv')\n",
    "df_phase_1 = pd.read_csv('s3://praekelt-static-resources/validation_aaq/validation_khumo_labelled.csv')\n",
    "df_phase_2 = pd.read_csv('s3://praekelt-static-resources/validation_aaq/validation_khumo_labelled_phase2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380f685",
   "metadata": {},
   "source": [
    "# Clean data\n",
    "\n",
    "## 1. Clean FAQs sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b015bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    'Validation questions - USER GENERATED': 'questions_usr',\n",
    "    'Validation questions - SYNTHETIC': 'questions_syn',\n",
    "    'FAQ Content': 'faq_content',\n",
    "    'FAQ Name': 'faq_name',\n",
    "    'FAQ title': 'faq_title',\n",
    "}\n",
    "faqs = faqs.rename(columns=column_map)\n",
    "faqs = faqs[column_map.values()]\n",
    "faqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6add5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.questions_usr.iloc[0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs[faqs.questions_usr.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b78bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = faqs[faqs.faq_name != 'FAQ Name']\n",
    "faqs = faqs[~faqs.questions_usr.isnull()]\n",
    "faqs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1ff83",
   "metadata": {},
   "source": [
    "I'm dropping FAQs with no \"user generated\" questions for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.loc[:, \"questions_usr\"] = faqs.questions_usr.apply(lambda x: np.asarray(x.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.loc[faqs.faq_name == \"Preg - ANAEMIA\", 'faq_name'] = \"Preg - Anemia\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9b4a4",
   "metadata": {},
   "source": [
    "Drop rows with too few questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.questions_usr.apply(lambda x: len(x)).hist(bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs[faqs.questions_usr.apply(lambda x: len(x)) < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f22fe",
   "metadata": {},
   "source": [
    "All Covid related.. seems ok to drop.\n",
    "\n",
    "Keep only FAQs with >=4 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = faqs[faqs.questions_usr.apply(lambda x: len(x)) >= 4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1ead6b",
   "metadata": {},
   "source": [
    "It's easier to keep the FAQ questions in an \"unexploded\" form.\n",
    "\n",
    "Split the synthetic questions into reference questions (which will be used to represent\n",
    "an FAQ in question-question matching) and training questions.\n",
    "To sample reference questions we'll randomly sample 2 indices from the questions for each FAQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b11523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "\n",
    "rs = RandomState(MT19937(SeedSequence(123456789)))\n",
    "\n",
    "def get_ref_split(l):\n",
    "    r = np.arange(len(l))\n",
    "    rs.shuffle(r)\n",
    "    return r[:2], r[2:]\n",
    "\n",
    "faqs.loc[:, \"_splits\"] = faqs.questions_usr.apply(get_ref_split)\n",
    "faqs.loc[:, \"question_ref\"] = faqs.apply(lambda x: x.questions_usr[x._splits[0]], axis=1)\n",
    "faqs.loc[:, \"question\"] = faqs.apply(lambda x: x.questions_usr[x._splits[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9518a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['question', 'question_ref', 'questions_usr',]:\n",
    "    faqs[col] = faqs[col].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea33488",
   "metadata": {},
   "source": [
    "## 2. Clean validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c810789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phase_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phase_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phase_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08348d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_map = {\n",
    "    'FAQ Name': 'faq_name',\n",
    "    'Question': 'question',\n",
    "    \n",
    "}\n",
    "df_ref_cols = ['question_msg_id', '_vnd_v1_chat_owner_anon', 'question_inserted_at', 'answer_msg_id', 'answer_inserted_at']\n",
    "df = pd.concat([df_phase_1, df_phase_2])\n",
    "df = df[df_ref_cols + list(df_column_map.keys())].rename(columns=df_column_map)\n",
    "df = df[df.faq_name.notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db369f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['question_inserted_at', 'answer_inserted_at']\n",
    "df[cols] = df[cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['question_inserted_at', 'answer_inserted_at']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a19ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 16))\n",
    "df.groupby('faq_name').size().plot(kind='barh', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df.merge(faqs.drop(columns=['question']), how=\"left\")\n",
    "merged[merged.questions_usr.isnull()].faq_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a476bd",
   "metadata": {},
   "source": [
    "Some FAQs don't match to the FAQ sheet, we'll just drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0593b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(faqs.drop(columns=['question']))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[~df_merged.question.duplicated()]\n",
    "df_merged = df_merged[~df_merged.question.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.faq_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81711011",
   "metadata": {},
   "source": [
    "Note: the question_usr column hasn't been exploded yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21984364",
   "metadata": {},
   "source": [
    "# Create Q-A relevance scoring dataset\n",
    "\n",
    "* Train (base: `faqs`)\n",
    "  * Use (`question_ref`, `faq_content`), explode `question_ref`\n",
    "  * Use (`question`, `faq_content`), explode `question`\n",
    "  * For each unique `faq_content`) sample 5~6 wrong `question`/`question_ref`'s\n",
    "* Test (base: `df_merged`)\n",
    "  * Use (`question`, `faq_content`)\n",
    "  * Use (`question`, wrong `faq_content`) to get ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632fa3d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687280b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train_ref = faqs.drop(\n",
    "    columns='question'\n",
    ").explode(\n",
    "    'question_ref'\n",
    ").rename(\n",
    "    columns={'question_ref': 'question'}\n",
    ").copy()\n",
    "\n",
    "cols = ['question', 'faq_content', 'faq_name']\n",
    "qa_train_ref = qa_train_ref[cols]\n",
    "qa_train_rest = faqs.explode('question')[cols].copy()\n",
    "\n",
    "qa_train_pos = pd.concat([qa_train_ref, qa_train_rest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train_rest[qa_train_rest.question.apply(lambda x: isinstance(x, list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "\n",
    "for faq_name, qdf in qa_train_pos.groupby('faq_name'):\n",
    "    # For each FAQ content, sample \"wrong\" questions\n",
    "    neg_df = qa_train_pos[qa_train_pos.faq_name != faq_name].copy() # all \"wrong\" questions\n",
    "    neg_df_sampled = neg_df.assign(faq_content=qdf['faq_content'].iloc[0], faq_name=faq_name).sample(6)\n",
    "    negative_samples.append(neg_df_sampled)\n",
    "    \n",
    "qa_train_neg = pd.concat(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518999d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1701110",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train = pd.concat([qa_train_pos.assign(label=1), qa_train_neg.assign(label=0)])\n",
    "qa_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802e789",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test_pos = df_merged.assign(label=1).copy()\n",
    "qa_test_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ceaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test_pos[qa_test_pos.question.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37df23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "\n",
    "for question, qdf in qa_test_pos.groupby(\"question\"):\n",
    "    # For each question we want to infer on all possible FAQs\n",
    "    faq_name = qdf.faq_name.iloc[0]\n",
    "    faq_content = qdf.faq_content.iloc[0]\n",
    "    neg_df = faqs[faqs.faq_name!= faq_name].drop(columns=['question']).copy()\n",
    "    neg_df = neg_df.assign(question=question, label=0)\n",
    "    negative_samples.append(neg_df)\n",
    "    \n",
    "qa_test_neg = pd.concat(negative_samples)\n",
    "\n",
    "qa_test = pd.concat([qa_test_pos, qa_test_neg])\n",
    "qa_test_short = qa_test.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test_pos.shape, qa_test_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test.faq_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5dae4",
   "metadata": {},
   "source": [
    "Check each unique question has 150 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e37bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_per_q = qa_test.groupby('question').size()\n",
    "num_rows_per_q[num_rows_per_q != 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test_short.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae26f4",
   "metadata": {},
   "source": [
    "# Create Q-Q semantic matching dataset\n",
    "\n",
    "* Train (base: `faqs`)\n",
    "  * Use (`question`, `question_ref`), explode both\n",
    "  * For each unique `qustion_ref`, sample 5~6 wrong `question` / `question_ref`'s\n",
    "* Test (base: `df_merged`)\n",
    "  * Use (`question`, `question_ref`), explode `question_ref`\n",
    "  * Use (`question`, wrong `faq_content`) to get ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_train_pos = faqs.explode('question').explode('question_ref').drop('_splits', axis=1).assign(label=1).copy()\n",
    "qq_train_pos = qq_train_pos[~qq_train_pos.question_ref.apply(lambda x: x=='')].reset_index(drop=True)\n",
    "qq_train_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f51f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "\n",
    "for question_ref, qdf in qq_train_pos.groupby(\"question_ref\"):\n",
    "    faq_name = qdf.faq_name.iloc[0]\n",
    "    faq_content = qdf.faq_content.iloc[0]\n",
    "    neg_df = qq_train_pos[\n",
    "        qq_train_pos.faq_name != faq_name\n",
    "    ].assign(\n",
    "        label=0, \n",
    "        faq_name=faq_name, \n",
    "        faq_content=faq_content, \n",
    "        question_ref=question_ref\n",
    "    ).sample(5).copy()\n",
    "    negative_samples.append(neg_df)\n",
    "    \n",
    "qq_train_neg = pd.concat(negative_samples).reset_index(drop=True)\n",
    "qq_train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['question', 'faq_name', 'faq_content', 'question_ref', 'label']\n",
    "qq_train = pd.concat([qq_train_pos[cols], qq_train_neg[cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f85d0",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test_pos = df_merged.explode('question_ref').assign(label=1)\n",
    "qq_test_pos = qq_test_pos[qq_test_pos.question_ref != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2900132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.question_msg_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62029e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "\n",
    "for question, qdf in qq_test_pos.groupby(\"question\"):\n",
    "    neg_df = faqs[faqs.faq_name!= qdf.faq_name.iloc[0]].copy()\n",
    "    neg_df = neg_df.explode('question_ref').assign(question=question, label=0)\n",
    "    negative_samples.append(neg_df)\n",
    "\n",
    "qq_test_neg = pd.concat(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70024a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test = pd.concat([qq_test_pos, qq_test_neg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8dc5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test_short = qq_test.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test.groupby('question').size()[qq_test.groupby('question').size() != 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ee759",
   "metadata": {},
   "outputs": [],
   "source": [
    "(qq_test.groupby('question').size() == faqs.explode('question_ref').shape[0]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17e03c",
   "metadata": {},
   "source": [
    "Some `question_ref`'s were empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _df in [qa_train, qa_test, qa_test_short, qq_train, qq_test, qq_test_short]:\n",
    "    _df.loc[:, \"question\"] = _df.question.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973c1c9",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize_qq(examples):\n",
    "    return tokenizer(\n",
    "        examples['question'], \n",
    "        examples['question_ref'], \n",
    "        max_length=384,\n",
    "        padding='max_length',\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=False,\n",
    "    )\n",
    "\n",
    "def custom_tokenize_qa(examples):\n",
    "    return tokenizer(\n",
    "        examples['question'], \n",
    "        examples['faq_content'], \n",
    "        max_length=384,\n",
    "        padding='max_length',\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424112ec",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train_dataset = Dataset.from_pandas(qa_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_test_dataset = Dataset.from_pandas(qa_test)\n",
    "qa_test_dataset_short = Dataset.from_pandas(qa_test_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns = ['question', 'faq_content', '__index_level_0__',]\n",
    "\n",
    "qa_tkn_train_dataset = qa_train_dataset.map(custom_tokenize_qa, batched=True, batch_size=1000, remove_columns=remove_columns)\n",
    "qa_tkn_test_dataset_short = qa_test_dataset_short.map(custom_tokenize_qa, batched=True, batch_size=1000, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tkn_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff66282",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tkn_test_dataset_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947f896",
   "metadata": {},
   "source": [
    "### QA Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_bucket = 'praekelt-static-resources'\n",
    "s3_prefix_fmt ='experiment/data/mc/{task_type}'\n",
    "\n",
    "task_type = 'question-answer-matching'\n",
    "s3_prefix = s3_prefix_fmt.format(task_type=task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d46cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "qa_training_input_path = f's3://{s3_bucket}/{s3_prefix}/train'\n",
    "qa_tkn_train_dataset.save_to_disk(qa_training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "qa_test_short_input_path = f's3://{s3_bucket}/{s3_prefix}/test_short'\n",
    "qa_tkn_test_dataset_short.save_to_disk(qa_test_short_input_path,fs=s3)\n",
    "\n",
    "# save untokenized train_dataset to s3\n",
    "qa_training_input_path = f's3://{s3_bucket}/{s3_prefix}/train_untokenized'\n",
    "qa_train_dataset.save_to_disk(qa_training_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save untokenized test_dataset to s3\n",
    "qa_test_input_path = f's3://{s3_bucket}/{s3_prefix}/test_untokenized'\n",
    "qa_test_dataset.save_to_disk(qa_test_input_path,fs=s3)\n",
    "\n",
    "# save untokenized short test_dataset to s3\n",
    "qa_test_short_input_path = f's3://{s3_bucket}/{s3_prefix}/test_untokenized_short'\n",
    "qa_test_dataset_short.save_to_disk(qa_test_short_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_tkn_train_dataset, qa_tkn_test_dataset_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafe99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6768317",
   "metadata": {},
   "source": [
    "### QQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test_short.question = qq_test_short.question.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ff95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test.question = qq_test.question.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_train_dataset = Dataset.from_pandas(qq_train)\n",
    "qq_test_dataset = Dataset.from_pandas(qq_test)\n",
    "\n",
    "remove_columns = ['question', 'question_ref', '__index_level_0__',]\n",
    "qq_tkn_train_dataset = qq_train_dataset.map(custom_tokenize_qq, batched=True, batch_size=1000, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba87bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_test_dataset_short = Dataset.from_pandas(qq_test_short)\n",
    "remove_columns = ['question_msg_id', '_vnd_v1_chat_owner_anon', 'question_inserted_at', 'answer_msg_id', 'answer_inserted_at', 'question', 'questions_usr', 'questions_syn', 'faq_content', 'faq_title', '_splits', 'question_ref', '__index_level_0__']\n",
    "qq_tkn_test_dataset_short = qq_test_dataset_short.map(custom_tokenize_qq, batched=True, batch_size=1000, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'question-question-matching'\n",
    "s3_prefix = s3_prefix_fmt.format(task_type=task_type)\n",
    "\n",
    "# save train_dataset to s3\n",
    "qq_training_input_path = f's3://{s3_bucket}/{s3_prefix}/train'\n",
    "qq_tkn_train_dataset.save_to_disk(qq_training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "qq_test_short_input_path = f's3://{s3_bucket}/{s3_prefix}/test_short'\n",
    "qq_tkn_test_dataset_short.save_to_disk(qq_test_short_input_path,fs=s3)\n",
    "\n",
    "# save untokenized train_dataset to s3\n",
    "qq_training_input_path = f's3://{s3_bucket}/{s3_prefix}/train_untokenized'\n",
    "qq_train_dataset.save_to_disk(qq_training_input_path,fs=s3)\n",
    "\n",
    "# save untokenized test_dataset to s3\n",
    "qq_test_input_path = f's3://{s3_bucket}/{s3_prefix}/test_untokenized'\n",
    "qq_test_dataset.save_to_disk(qq_test_input_path,fs=s3)\n",
    "\n",
    "# save untokenized short test_dataset to s3\n",
    "qq_test_short_input_path = f's3://{s3_bucket}/{s3_prefix}/test_untokenized_short'\n",
    "qq_test_dataset_short.save_to_disk(qq_test_short_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2178538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Mar 26 2022, 15:51:15) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

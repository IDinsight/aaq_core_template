{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83918a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e73970",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = pd.read_csv(\"s3://praekelt-static-resources/experiment/data/yal_faqmatches.csv\")\n",
    "faqs = faqs[~faqs.faq_title.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b40416",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    (pd.read_csv(f\"s3://praekelt-static-resources/yal_validation/yal_validation_questions_batch_{n}.csv\") \n",
    "     for n in [1, 2])\n",
    "    , axis=0\n",
    ").drop(columns=[\"Unnamed: 0\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83edae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"faq_title\").size().hist(bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6dea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.faq_title.nunique(), faqs.faq_title.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a55f2",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(faqs, left_on=\"faq_title\", right_on=\"faq_title\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5119f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5b0d8",
   "metadata": {},
   "source": [
    "Which rows got dropped during merging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.faq_title.isin(faqs.faq_title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f02100",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_token_lengths = df_merged.faq_content_to_send.apply(lambda text: len(text.split()))\n",
    "faq_token_lengths.hist(bins=10);\n",
    "print(f\"FAQ token lengths: {faq_token_lengths.min()} ~ {faq_token_lengths.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged.question.duplicated(keep=False)].sort_values(by='question')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea549ff",
   "metadata": {},
   "source": [
    "# For Question-Answer Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57b2ba",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "keep_columns = ['question', 'faq_title', 'faq_id', 'faq_content_to_send']\n",
    "df_merged = df_merged[keep_columns]\n",
    "positive_train_df, test_df = train_test_split(df_merged, test_size=0.3, stratify=df_merged.faq_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a648e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(\"faq_title\").size().hist(bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d844c",
   "metadata": {},
   "source": [
    "## Negative Sampling\n",
    "\n",
    "We should select negative samples only within training data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f46d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "for cur_id, _df in positive_train_df.groupby(\"faq_id\"):\n",
    "    cur_negative_samples = positive_train_df[positive_train_df.faq_id != cur_id].sample(10)\n",
    "    cur_negative_samples['faq_id'] = cur_id\n",
    "    cur_negative_samples['faq_title'] = faqs.loc[faqs.faq_id == cur_id, \"faq_title\"].iloc[0]\n",
    "    cur_negative_samples['faq_content_to_send'] = faqs.loc[faqs.faq_id == cur_id, \"faq_content_to_send\"].iloc[0]\n",
    "    negative_samples.append(cur_negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = pd.concat(negative_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples.question.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82337f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = positive_train_df\n",
    "positive_samples['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fba2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([negative_samples, positive_samples],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1195043",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc3557",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcdaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55709f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "94*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090c6ad",
   "metadata": {},
   "source": [
    "## Preprocessing for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(examples):\n",
    "    return tokenizer(\n",
    "        examples['question'], \n",
    "        examples['faq_content_to_send'], \n",
    "        max_length=384,\n",
    "        padding='max_length',\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        stride=128,\n",
    "    )\n",
    "\n",
    "remove_columns = ['question', 'faq_id', 'faq_title', 'faq_content_to_send', '__index_level_0__']\n",
    "simple_tokenized_train_dataset = train_dataset.map(custom_tokenize, batched=True, batch_size=1000, remove_columns=remove_columns)\n",
    "simple_tokenized_test_dataset = test_dataset.map(custom_tokenize, batched=True, batch_size=1000, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bfefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "s3_prefix='experiment/data/automodel_classification_split'\n",
    "\n",
    "# save train_dataset to s3\n",
    "simple_training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train_with_neg'\n",
    "simple_tokenized_train_dataset.save_to_disk(simple_training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "simple_test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test_with_neg'\n",
    "simple_tokenized_test_dataset.save_to_disk(simple_test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix='experiment/data/untokenized_split'\n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train_with_neg'\n",
    "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test_with_neg'\n",
    "test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b922de4",
   "metadata": {},
   "source": [
    "## Preprocessing for Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"faq_content_to_send\"],\n",
    "        examples[\"faq_content_to_send\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"faq_content_to_send\"][sample_index]\n",
    "        is_positive = examples[\"label\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if is_positive == 0.0:\n",
    "           tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "           tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = 0\n",
    "            end_char = start_char + len(answers)\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns = ['question', 'faq_id', 'label', 'faq_title', 'faq_content_to_send', '__index_level_0__']\n",
    "tokenized_train_dataset = train_dataset.map(prepare_train_features, batched=True, batch_size=1000, remove_columns=remove_columns)\n",
    "tokenized_test_dataset = test_dataset.map(prepare_train_features, batched=True, batch_size=1000, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'experiment/data/automodel_split'\n",
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train_with_neg'\n",
    "tokenized_train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test_with_neg'\n",
    "tokenized_test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_path == 's3://sagemaker-af-south-1-678681925278/experiment/data/automodel_split/train_with_neg'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
